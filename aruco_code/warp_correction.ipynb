{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of each possible ArUco tag OpenCV supports\n",
    "ARUCO_DICT = {\n",
    "\t\"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
    "\t\"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
    "\t\"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
    "\t\"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
    "\t\"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
    "\t\"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
    "\t\"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
    "\t\"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
    "\t\"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
    "\t\"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
    "\t\"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
    "\t\"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
    "\t\"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
    "\t\"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
    "\t\"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
    "\t\"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
    "\t\"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL,\n",
    "\t\"DICT_APRILTAG_16h5\": cv2.aruco.DICT_APRILTAG_16h5,\n",
    "\t\"DICT_APRILTAG_25h9\": cv2.aruco.DICT_APRILTAG_25h9,\n",
    "\t\"DICT_APRILTAG_36h10\": cv2.aruco.DICT_APRILTAG_36h10,\n",
    "\t\"DICT_APRILTAG_36h11\": cv2.aruco.DICT_APRILTAG_36h11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = \"jans_webcam\"\n",
    "cam_input = 0 # 0 for webcam, 1 for phone\n",
    "aruco_dict = ARUCO_DICT[\"DICT_7X7_50\"]\n",
    "aruco_size = 0.079375 # in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get calibration parameters\n",
    "\n",
    "# Path to pickle file\n",
    "calib_file_path = \"../cam_calibration/cameras/\" + camera + \"/calibration_params.pickle\"\n",
    "\n",
    "# Load the calibration parameters from the pickle file\n",
    "with open(calib_file_path, 'rb') as f:\n",
    "    calibration_params = pickle.load(f)\n",
    "\n",
    "# Extract the parameters from the dictionary\n",
    "mtx = calibration_params[\"mtx\"]\n",
    "dist = calibration_params[\"dist\"]\n",
    "calib_w = calibration_params[\"calib_w\"]\n",
    "calib_h = calibration_params[\"calib_h\"]\n",
    "\n",
    "if any(x is None for x in (mtx, dist)):\n",
    "    print(\"Failed to retrieve calibration parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwarp(matrix, distort, cam_input, aruco_dict, aruco_size):\n",
    "    \n",
    "    # Set up video capture from default camera\n",
    "    cap = cv2.VideoCapture(cam_input)\n",
    "\n",
    "    # ret, frame = cap.read()\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f\"Resolution = {width}x{height}\")\n",
    "\n",
    "    roi_corners = {}\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print('No image found')\n",
    "            break\n",
    "\n",
    "        # operations on the frame come here\n",
    "        frame = cv2.resize(frame, (calib_w,calib_h))\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "        \n",
    "        aruco_dict_def = cv2.aruco.getPredefinedDictionary(aruco_dict)\n",
    "        \n",
    "        # lists of ids and the corners beloning to each id\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, aruco_dict_def)\n",
    "        \n",
    "        if np.all(ids is not None):  # If there are markers found by detector\n",
    "\n",
    "            tvecs = []\n",
    "            rvecs = []\n",
    "            for id in ids:  # Iterate in markers\n",
    "                index = np.where(ids == id)[0][0]\n",
    "                if id == 1:\n",
    "                    roi_corners[\"A\"] = [int(corners[index][0][2][0]), int(corners[index][0][2][1])] # Bottom right corner of ID 1\n",
    "                if id == 2:\n",
    "                    roi_corners[\"D\"] = [int(corners[index][0][3][0]), int(corners[index][0][3][1])] # Bottom left corner of ID 2\n",
    "                if id == 3:\n",
    "                    roi_corners[\"C\"] = [int(corners[index][0][0][0]), int(corners[index][0][0][1])] # Top left corner of ID 3\n",
    "                if id == 4:\n",
    "                    roi_corners[\"B\"] = [int(corners[index][0][1][0]), int(corners[index][0][1][1])] # Top right corner of ID 4\n",
    "\n",
    "                # Estimate pose of each marker and return the values rvec and tvec---different from camera coefficients\n",
    "                rvec, tvec, _ = aruco.estimatePoseSingleMarkers(corners[index], aruco_size, matrix, distort)\n",
    "                tvecs.append(tvec)\n",
    "                rvecs.append(rvec)\n",
    "                (rvec - tvec).any()  # get rid of that nasty numpy value array error\n",
    "\n",
    "                if not all(id in ids for id in [1,2,3,4]):\n",
    "                    cv2.drawFrameAxes(frame, matrix, distort, rvec, tvec, 0.1, 2)  # Draw Axis\n",
    "                    for corner in corners:\n",
    "                        cv2.putText(frame, \n",
    "                                f\"Dist: {round(np.linalg.norm(tvec[0][0]), 2)} m\", \n",
    "                                corner[0][1].astype(int), \n",
    "                                cv2.FONT_HERSHEY_PLAIN, 1.3, (0, 0, 255), 2, \n",
    "                                cv2.LINE_AA,\n",
    "                        )\n",
    "\n",
    "                                    \n",
    "            if all(id in ids for id in [1,2,3,4]):\n",
    "\n",
    "                indexA = np.where(ids == 1)[0][0]\n",
    "                indexB = np.where(ids == 4)[0][0]\n",
    "                indexC = np.where(ids == 3)[0][0]\n",
    "                indexD = np.where(ids == 2)[0][0]\n",
    "\n",
    "                width_AB = np.linalg.norm(tvecs[indexA]-tvecs[indexB]) - aruco_size\n",
    "                width_CD = np.linalg.norm(tvecs[indexC]-tvecs[indexD]) - aruco_size\n",
    "                corners_width = max(width_AB, width_CD)\n",
    "\n",
    "                height_AD = np.linalg.norm(tvecs[indexA]-tvecs[indexD]) - aruco_size\n",
    "                height_BC = np.linalg.norm(tvecs[indexB]-tvecs[indexC]) - aruco_size\n",
    "                corners_height = max(height_AD, height_BC)\n",
    "\n",
    "\n",
    "                # Resize image\n",
    "                max_width = 1280\n",
    "                max_height = 960\n",
    "                scale = corners_height / corners_width\n",
    "                # scale = min(max_width / corners_width, max_height / corners_height)\n",
    "\n",
    "                if max_height * scale > max_width:\n",
    "                    new_width = max_width\n",
    "                    new_height = int(max_width / scale)\n",
    "                else:\n",
    "                    new_height = max_height\n",
    "                    new_width = int(max_height * scale)\n",
    "\n",
    "                input_pts = np.float32([roi_corners[\"A\"], roi_corners[\"B\"], roi_corners[\"C\"], roi_corners[\"D\"]])\n",
    "                output_pts = np.float32([[0, 0],\n",
    "                                        [0, new_height - 1],\n",
    "                                        [new_width - 1, new_height - 1],\n",
    "                                        [new_width - 1, 0]])\n",
    "                \n",
    "                # Compute the perspective transform M\n",
    "                M = cv2.getPerspectiveTransform(input_pts,output_pts)\n",
    "                frame = cv2.warpPerspective(frame,M,(new_width, new_height),flags=cv2.INTER_LINEAR)\n",
    "            \n",
    "            else:\n",
    "                aruco.drawDetectedMarkers(frame, corners)  # Draw A square around the markers\n",
    "                # Resize image\n",
    "                max_width = 1280\n",
    "                max_height = 960\n",
    "                scale = min(max_width / width, max_height / height)\n",
    "                \n",
    "                frame = cv2.resize(frame, (int(width*scale), int(height*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', frame)\n",
    "        # Exit if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution = 640x360\n"
     ]
    }
   ],
   "source": [
    "unwarp(mtx, dist, cam_input, aruco_dict, aruco_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
